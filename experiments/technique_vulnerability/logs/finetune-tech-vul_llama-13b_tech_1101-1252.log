2025-11-01 12:52:40,444 INFO     ----------Arguments-----------
2025-11-01 12:52:40,444 INFO     model = llama-13b
2025-11-01 12:52:40,444 INFO     mode = train
2025-11-01 12:52:40,444 INFO     temp = 0.1
2025-11-01 12:52:40,444 INFO     top_p = 0.5
2025-11-01 12:52:40,444 INFO     penal = 0.0
2025-11-01 12:52:40,444 INFO     log_dir = ./logs
2025-11-01 12:52:40,444 INFO     epoch = 5
2025-11-01 12:52:40,444 INFO     train_batch_size = 8
2025-11-01 12:52:40,444 INFO     valid_batch_size = 8
2025-11-01 12:52:40,444 INFO     lr = 0.0001
2025-11-01 12:52:40,444 INFO     measure = tech
2025-11-01 12:52:40,444 INFO     train_data = mentalmanip
2025-11-01 12:52:40,444 INFO     eval_data = mentalmanip_con
2025-11-01 12:52:40,444 INFO     ------------------------------

2025-11-01 12:52:40,465 INFO     -----MentalManip Dataset Information-----
2025-11-01 12:52:40,465 INFO     Total size = 1748
2025-11-01 12:52:40,465 INFO     Train size = 1048
2025-11-01 12:52:40,465 INFO     Valid size = 349
2025-11-01 12:52:40,465 INFO     Test size = 351
2025-11-01 12:52:40,465 INFO     
2025-11-01 12:52:40,465 INFO     -----Finetuning Data Size Information-----
2025-11-01 12:52:40,465 INFO     Train size: 1048
2025-11-01 12:52:40,465 INFO     Valid size: 349
2025-11-01 12:52:40,465 INFO     Test size: 351
2025-11-01 12:52:40,465 INFO     
2025-11-01 12:55:24,943 INFO     Epoch: 0
2025-11-01 12:55:24,943 INFO     Best checkpoint: None, Best f1: None
2025-11-01 12:55:24,943 INFO     {'loss': 1.6459, 'learning_rate': 0.0001, 'epoch': 0.15}
2025-11-01 12:57:34,043 INFO     Epoch: 0
2025-11-01 12:57:34,044 INFO     Best checkpoint: None, Best f1: None
2025-11-01 12:57:34,044 INFO     {'loss': 1.2005, 'learning_rate': 0.0001, 'epoch': 0.31}
2025-11-01 12:59:44,453 INFO     Epoch: 0
2025-11-01 12:59:44,453 INFO     Best checkpoint: None, Best f1: None
2025-11-01 12:59:44,453 INFO     {'loss': 0.5818, 'learning_rate': 0.0001, 'epoch': 0.46}
2025-11-01 13:02:19,289 INFO     Epoch: 0
2025-11-01 13:02:19,289 INFO     Best checkpoint: None, Best f1: None
2025-11-01 13:02:19,289 INFO     {'loss': 0.3875, 'learning_rate': 0.0001, 'epoch': 0.61}
2025-11-01 13:04:37,268 INFO     Epoch: 0
2025-11-01 13:04:37,268 INFO     Best checkpoint: None, Best f1: None
2025-11-01 13:04:37,268 INFO     {'loss': 0.3666, 'learning_rate': 0.0001, 'epoch': 0.76}
2025-11-01 13:06:48,841 INFO     Epoch: 0
2025-11-01 13:06:48,841 INFO     Best checkpoint: None, Best f1: None
2025-11-01 13:06:48,841 INFO     {'loss': 0.3524, 'learning_rate': 0.0001, 'epoch': 0.92}
2025-11-01 13:09:07,565 INFO     Epoch: 1
2025-11-01 13:09:07,565 INFO     Best checkpoint: None, Best f1: None
2025-11-01 13:09:07,565 INFO     {'loss': 0.3024, 'learning_rate': 0.0001, 'epoch': 1.07}
2025-11-01 13:11:14,122 INFO     Epoch: 1
2025-11-01 13:11:14,122 INFO     Best checkpoint: None, Best f1: None
2025-11-01 13:11:14,122 INFO     {'loss': 0.2902, 'learning_rate': 0.0001, 'epoch': 1.22}
2025-11-01 13:13:27,189 INFO     Epoch: 1
2025-11-01 13:13:27,189 INFO     Best checkpoint: None, Best f1: None
2025-11-01 13:13:27,189 INFO     {'loss': 0.3145, 'learning_rate': 0.0001, 'epoch': 1.37}
2025-11-01 13:15:53,495 INFO     Epoch: 1
2025-11-01 13:15:53,496 INFO     Best checkpoint: None, Best f1: None
2025-11-01 13:15:53,496 INFO     {'loss': 0.2968, 'learning_rate': 0.0001, 'epoch': 1.53}
2025-11-01 13:18:04,346 INFO     Epoch: 1
2025-11-01 13:18:04,346 INFO     Best checkpoint: None, Best f1: None
2025-11-01 13:18:04,346 INFO     {'loss': 0.3043, 'learning_rate': 0.0001, 'epoch': 1.68}
2025-11-01 13:20:21,868 INFO     Epoch: 1
2025-11-01 13:20:21,868 INFO     Best checkpoint: None, Best f1: None
2025-11-01 13:20:21,868 INFO     {'loss': 0.2643, 'learning_rate': 0.0001, 'epoch': 1.83}
2025-11-01 13:22:53,984 INFO     Epoch: 1
2025-11-01 13:22:53,984 INFO     Best checkpoint: None, Best f1: None
2025-11-01 13:22:53,984 INFO     {'loss': 0.2711, 'learning_rate': 0.0001, 'epoch': 1.98}
2025-11-01 13:25:19,972 INFO     Epoch: 2
2025-11-01 13:25:19,972 INFO     Best checkpoint: None, Best f1: None
2025-11-01 13:25:19,972 INFO     {'loss': 0.2478, 'learning_rate': 0.0001, 'epoch': 2.14}
2025-11-01 13:27:35,910 INFO     Epoch: 2
2025-11-01 13:27:35,910 INFO     Best checkpoint: None, Best f1: None
2025-11-01 13:27:35,910 INFO     {'loss': 0.247, 'learning_rate': 0.0001, 'epoch': 2.29}
2025-11-01 13:29:44,254 INFO     Epoch: 2
2025-11-01 13:29:44,254 INFO     Best checkpoint: None, Best f1: None
2025-11-01 13:29:44,254 INFO     {'loss': 0.2567, 'learning_rate': 0.0001, 'epoch': 2.44}
2025-11-01 13:31:55,213 INFO     Epoch: 2
2025-11-01 13:31:55,213 INFO     Best checkpoint: None, Best f1: None
2025-11-01 13:31:55,213 INFO     {'loss': 0.2567, 'learning_rate': 0.0001, 'epoch': 2.6}
2025-11-01 13:34:03,978 INFO     Epoch: 2
2025-11-01 13:34:03,979 INFO     Best checkpoint: None, Best f1: None
2025-11-01 13:34:03,979 INFO     {'loss': 0.2368, 'learning_rate': 0.0001, 'epoch': 2.75}
2025-11-01 13:36:24,839 INFO     Epoch: 2
2025-11-01 13:36:24,839 INFO     Best checkpoint: None, Best f1: None
2025-11-01 13:36:24,839 INFO     {'loss': 0.2353, 'learning_rate': 0.0001, 'epoch': 2.9}
2025-11-01 13:38:58,910 INFO     Epoch: 3
2025-11-01 13:38:58,910 INFO     Best checkpoint: None, Best f1: None
2025-11-01 13:38:58,911 INFO     {'loss': 0.254, 'learning_rate': 0.0001, 'epoch': 3.05}
2025-11-01 13:41:14,372 INFO     Epoch: 3
2025-11-01 13:41:14,372 INFO     Best checkpoint: None, Best f1: None
2025-11-01 13:41:14,373 INFO     {'loss': 0.2025, 'learning_rate': 0.0001, 'epoch': 3.21}
2025-11-01 13:43:24,124 INFO     Epoch: 3
2025-11-01 13:43:24,124 INFO     Best checkpoint: None, Best f1: None
2025-11-01 13:43:24,124 INFO     {'loss': 0.2042, 'learning_rate': 0.0001, 'epoch': 3.36}
2025-11-01 13:45:47,048 INFO     Epoch: 3
2025-11-01 13:45:47,048 INFO     Best checkpoint: None, Best f1: None
2025-11-01 13:45:47,048 INFO     {'loss': 0.2098, 'learning_rate': 0.0001, 'epoch': 3.51}
2025-11-01 13:47:59,267 INFO     Epoch: 3
2025-11-01 13:47:59,267 INFO     Best checkpoint: None, Best f1: None
2025-11-01 13:47:59,267 INFO     {'loss': 0.222, 'learning_rate': 0.0001, 'epoch': 3.66}
2025-11-01 13:50:31,528 INFO     Epoch: 3
2025-11-01 13:50:31,529 INFO     Best checkpoint: None, Best f1: None
2025-11-01 13:50:31,529 INFO     {'loss': 0.1982, 'learning_rate': 0.0001, 'epoch': 3.82}
2025-11-01 13:52:43,041 INFO     Epoch: 3
2025-11-01 13:52:43,041 INFO     Best checkpoint: None, Best f1: None
2025-11-01 13:52:43,041 INFO     {'loss': 0.2062, 'learning_rate': 0.0001, 'epoch': 3.97}
2025-11-01 13:54:59,143 INFO     Epoch: 4
2025-11-01 13:54:59,143 INFO     Best checkpoint: None, Best f1: None
2025-11-01 13:54:59,143 INFO     {'loss': 0.1632, 'learning_rate': 0.0001, 'epoch': 4.12}
2025-11-01 13:57:39,862 INFO     Epoch: 4
2025-11-01 13:57:39,862 INFO     Best checkpoint: None, Best f1: None
2025-11-01 13:57:39,862 INFO     {'loss': 0.1457, 'learning_rate': 0.0001, 'epoch': 4.27}
2025-11-01 13:59:48,324 INFO     Epoch: 4
2025-11-01 13:59:48,324 INFO     Best checkpoint: None, Best f1: None
2025-11-01 13:59:48,324 INFO     {'loss': 0.1515, 'learning_rate': 0.0001, 'epoch': 4.43}
2025-11-01 14:02:09,930 INFO     Epoch: 4
2025-11-01 14:02:09,930 INFO     Best checkpoint: None, Best f1: None
2025-11-01 14:02:09,930 INFO     {'loss': 0.1814, 'learning_rate': 0.0001, 'epoch': 4.58}
2025-11-01 14:04:21,813 INFO     Epoch: 4
2025-11-01 14:04:21,813 INFO     Best checkpoint: None, Best f1: None
2025-11-01 14:04:21,813 INFO     {'loss': 0.1702, 'learning_rate': 0.0001, 'epoch': 4.73}
2025-11-01 14:06:39,556 INFO     Epoch: 4
2025-11-01 14:06:39,556 INFO     Best checkpoint: None, Best f1: None
2025-11-01 14:06:39,556 INFO     {'loss': 0.179, 'learning_rate': 0.0001, 'epoch': 4.89}
2025-11-01 14:07:50,419 INFO     Epoch: 4
2025-11-01 14:07:50,419 INFO     Best checkpoint: None, Best f1: None
2025-11-01 14:07:50,419 INFO     {'train_runtime': 4479.1658, 'train_samples_per_second': 1.17, 'train_steps_per_second': 0.073, 'train_loss': 0.3271165732237009, 'epoch': 4.96}
2025-11-01 14:07:50,680 INFO     Fine-tuned meta-llama/Llama-2-13b-chat-hf saved to llama_ft/mentalmanip!
