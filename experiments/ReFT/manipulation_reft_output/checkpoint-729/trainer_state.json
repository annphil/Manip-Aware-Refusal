{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 729,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.013717421124828532,
      "grad_norm": 7.102995872497559,
      "learning_rate": 0.003994513031550069,
      "loss": 7.909,
      "step": 10
    },
    {
      "epoch": 0.027434842249657063,
      "grad_norm": 5.449845790863037,
      "learning_rate": 0.003989026063100137,
      "loss": 4.2655,
      "step": 20
    },
    {
      "epoch": 0.0411522633744856,
      "grad_norm": 9.055180549621582,
      "learning_rate": 0.0039835390946502056,
      "loss": 3.5615,
      "step": 30
    },
    {
      "epoch": 0.05486968449931413,
      "grad_norm": 9.314657211303711,
      "learning_rate": 0.003978052126200274,
      "loss": 3.0856,
      "step": 40
    },
    {
      "epoch": 0.06858710562414266,
      "grad_norm": 19.166606903076172,
      "learning_rate": 0.003972565157750343,
      "loss": 2.6442,
      "step": 50
    },
    {
      "epoch": 0.0823045267489712,
      "grad_norm": 13.384329795837402,
      "learning_rate": 0.003967078189300412,
      "loss": 2.2823,
      "step": 60
    },
    {
      "epoch": 0.09602194787379972,
      "grad_norm": 16.77313995361328,
      "learning_rate": 0.00396159122085048,
      "loss": 1.9177,
      "step": 70
    },
    {
      "epoch": 0.10973936899862825,
      "grad_norm": 12.387334823608398,
      "learning_rate": 0.003956104252400549,
      "loss": 1.6896,
      "step": 80
    },
    {
      "epoch": 0.12345679012345678,
      "grad_norm": 14.599374771118164,
      "learning_rate": 0.003950617283950617,
      "loss": 1.6219,
      "step": 90
    },
    {
      "epoch": 0.13717421124828533,
      "grad_norm": 12.941634178161621,
      "learning_rate": 0.003945130315500686,
      "loss": 1.4573,
      "step": 100
    },
    {
      "epoch": 0.15089163237311384,
      "grad_norm": 14.008685111999512,
      "learning_rate": 0.003939643347050755,
      "loss": 1.1522,
      "step": 110
    },
    {
      "epoch": 0.1646090534979424,
      "grad_norm": 16.199888229370117,
      "learning_rate": 0.003934156378600823,
      "loss": 1.0397,
      "step": 120
    },
    {
      "epoch": 0.17832647462277093,
      "grad_norm": 18.411029815673828,
      "learning_rate": 0.003928669410150892,
      "loss": 1.1183,
      "step": 130
    },
    {
      "epoch": 0.19204389574759945,
      "grad_norm": 21.276185989379883,
      "learning_rate": 0.00392318244170096,
      "loss": 0.8733,
      "step": 140
    },
    {
      "epoch": 0.205761316872428,
      "grad_norm": 16.384662628173828,
      "learning_rate": 0.003917695473251029,
      "loss": 0.8043,
      "step": 150
    },
    {
      "epoch": 0.2194787379972565,
      "grad_norm": 17.66779327392578,
      "learning_rate": 0.003912208504801098,
      "loss": 0.6612,
      "step": 160
    },
    {
      "epoch": 0.23319615912208505,
      "grad_norm": 12.729955673217773,
      "learning_rate": 0.003906721536351166,
      "loss": 0.6627,
      "step": 170
    },
    {
      "epoch": 0.24691358024691357,
      "grad_norm": 10.72763442993164,
      "learning_rate": 0.0039012345679012347,
      "loss": 0.6115,
      "step": 180
    },
    {
      "epoch": 0.2606310013717421,
      "grad_norm": 19.470672607421875,
      "learning_rate": 0.0038957475994513035,
      "loss": 0.6592,
      "step": 190
    },
    {
      "epoch": 0.27434842249657065,
      "grad_norm": 9.79128360748291,
      "learning_rate": 0.003890260631001372,
      "loss": 0.4412,
      "step": 200
    },
    {
      "epoch": 0.2880658436213992,
      "grad_norm": 17.319538116455078,
      "learning_rate": 0.0038847736625514406,
      "loss": 0.4442,
      "step": 210
    },
    {
      "epoch": 0.3017832647462277,
      "grad_norm": 20.70102310180664,
      "learning_rate": 0.003879286694101509,
      "loss": 0.4374,
      "step": 220
    },
    {
      "epoch": 0.31550068587105623,
      "grad_norm": 11.593032836914062,
      "learning_rate": 0.0038737997256515777,
      "loss": 0.3548,
      "step": 230
    },
    {
      "epoch": 0.3292181069958848,
      "grad_norm": 10.380108833312988,
      "learning_rate": 0.0038683127572016465,
      "loss": 0.3424,
      "step": 240
    },
    {
      "epoch": 0.3429355281207133,
      "grad_norm": 9.524140357971191,
      "learning_rate": 0.003862825788751715,
      "loss": 0.3228,
      "step": 250
    },
    {
      "epoch": 0.35665294924554186,
      "grad_norm": 9.343277931213379,
      "learning_rate": 0.0038573388203017836,
      "loss": 0.2435,
      "step": 260
    },
    {
      "epoch": 0.37037037037037035,
      "grad_norm": 13.622091293334961,
      "learning_rate": 0.0038518518518518515,
      "loss": 0.2275,
      "step": 270
    },
    {
      "epoch": 0.3840877914951989,
      "grad_norm": 14.499710083007812,
      "learning_rate": 0.0038463648834019203,
      "loss": 0.3775,
      "step": 280
    },
    {
      "epoch": 0.39780521262002744,
      "grad_norm": 16.33543586730957,
      "learning_rate": 0.003840877914951989,
      "loss": 0.263,
      "step": 290
    },
    {
      "epoch": 0.411522633744856,
      "grad_norm": 10.830759048461914,
      "learning_rate": 0.0038353909465020574,
      "loss": 0.1856,
      "step": 300
    },
    {
      "epoch": 0.4252400548696845,
      "grad_norm": 6.924062728881836,
      "learning_rate": 0.0038299039780521262,
      "loss": 0.152,
      "step": 310
    },
    {
      "epoch": 0.438957475994513,
      "grad_norm": 6.442953109741211,
      "learning_rate": 0.003824417009602195,
      "loss": 0.1087,
      "step": 320
    },
    {
      "epoch": 0.45267489711934156,
      "grad_norm": 8.133803367614746,
      "learning_rate": 0.0038189300411522633,
      "loss": 0.1757,
      "step": 330
    },
    {
      "epoch": 0.4663923182441701,
      "grad_norm": 13.79932689666748,
      "learning_rate": 0.003813443072702332,
      "loss": 0.1208,
      "step": 340
    },
    {
      "epoch": 0.48010973936899864,
      "grad_norm": 10.184813499450684,
      "learning_rate": 0.0038079561042524005,
      "loss": 0.1287,
      "step": 350
    },
    {
      "epoch": 0.49382716049382713,
      "grad_norm": 3.2577786445617676,
      "learning_rate": 0.0038024691358024693,
      "loss": 0.1784,
      "step": 360
    },
    {
      "epoch": 0.5075445816186557,
      "grad_norm": 4.324190616607666,
      "learning_rate": 0.003796982167352538,
      "loss": 0.112,
      "step": 370
    },
    {
      "epoch": 0.5212620027434842,
      "grad_norm": 3.94382905960083,
      "learning_rate": 0.0037914951989026064,
      "loss": 0.1031,
      "step": 380
    },
    {
      "epoch": 0.5349794238683128,
      "grad_norm": 4.351624011993408,
      "learning_rate": 0.003786008230452675,
      "loss": 0.0946,
      "step": 390
    },
    {
      "epoch": 0.5486968449931413,
      "grad_norm": 0.9790947437286377,
      "learning_rate": 0.0037805212620027435,
      "loss": 0.1055,
      "step": 400
    },
    {
      "epoch": 0.5624142661179699,
      "grad_norm": 11.866278648376465,
      "learning_rate": 0.0037750342935528123,
      "loss": 0.0813,
      "step": 410
    },
    {
      "epoch": 0.5761316872427984,
      "grad_norm": 4.954287052154541,
      "learning_rate": 0.003769547325102881,
      "loss": 0.1122,
      "step": 420
    },
    {
      "epoch": 0.5898491083676269,
      "grad_norm": 3.6281094551086426,
      "learning_rate": 0.0037640603566529494,
      "loss": 0.0781,
      "step": 430
    },
    {
      "epoch": 0.6035665294924554,
      "grad_norm": 4.920687675476074,
      "learning_rate": 0.0037585733882030178,
      "loss": 0.1171,
      "step": 440
    },
    {
      "epoch": 0.6172839506172839,
      "grad_norm": 7.36521577835083,
      "learning_rate": 0.003753086419753086,
      "loss": 0.1346,
      "step": 450
    },
    {
      "epoch": 0.6310013717421125,
      "grad_norm": 3.5788347721099854,
      "learning_rate": 0.003747599451303155,
      "loss": 0.088,
      "step": 460
    },
    {
      "epoch": 0.644718792866941,
      "grad_norm": 3.4002041816711426,
      "learning_rate": 0.0037421124828532237,
      "loss": 0.0826,
      "step": 470
    },
    {
      "epoch": 0.6584362139917695,
      "grad_norm": 2.4556453227996826,
      "learning_rate": 0.003736625514403292,
      "loss": 0.0534,
      "step": 480
    },
    {
      "epoch": 0.6721536351165981,
      "grad_norm": 2.1229560375213623,
      "learning_rate": 0.003731138545953361,
      "loss": 0.0935,
      "step": 490
    },
    {
      "epoch": 0.6858710562414266,
      "grad_norm": 1.7936378717422485,
      "learning_rate": 0.0037256515775034296,
      "loss": 0.074,
      "step": 500
    },
    {
      "epoch": 0.6995884773662552,
      "grad_norm": 4.88102388381958,
      "learning_rate": 0.003720164609053498,
      "loss": 0.0567,
      "step": 510
    },
    {
      "epoch": 0.7133058984910837,
      "grad_norm": 2.9650697708129883,
      "learning_rate": 0.0037146776406035667,
      "loss": 0.042,
      "step": 520
    },
    {
      "epoch": 0.7270233196159122,
      "grad_norm": 3.334686040878296,
      "learning_rate": 0.003709190672153635,
      "loss": 0.085,
      "step": 530
    },
    {
      "epoch": 0.7407407407407407,
      "grad_norm": 10.097945213317871,
      "learning_rate": 0.003703703703703704,
      "loss": 0.0608,
      "step": 540
    },
    {
      "epoch": 0.7544581618655692,
      "grad_norm": 5.526248931884766,
      "learning_rate": 0.0036982167352537726,
      "loss": 0.0475,
      "step": 550
    },
    {
      "epoch": 0.7681755829903978,
      "grad_norm": 2.3787221908569336,
      "learning_rate": 0.003692729766803841,
      "loss": 0.0489,
      "step": 560
    },
    {
      "epoch": 0.7818930041152263,
      "grad_norm": 9.216018676757812,
      "learning_rate": 0.0036872427983539098,
      "loss": 0.2081,
      "step": 570
    },
    {
      "epoch": 0.7956104252400549,
      "grad_norm": 3.5417046546936035,
      "learning_rate": 0.003681755829903978,
      "loss": 0.0483,
      "step": 580
    },
    {
      "epoch": 0.8093278463648834,
      "grad_norm": 2.9877257347106934,
      "learning_rate": 0.003676268861454047,
      "loss": 0.0465,
      "step": 590
    },
    {
      "epoch": 0.823045267489712,
      "grad_norm": 2.1434154510498047,
      "learning_rate": 0.0036707818930041157,
      "loss": 0.0446,
      "step": 600
    },
    {
      "epoch": 0.8367626886145405,
      "grad_norm": 0.45098498463630676,
      "learning_rate": 0.0036652949245541836,
      "loss": 0.0276,
      "step": 610
    },
    {
      "epoch": 0.850480109739369,
      "grad_norm": 1.5228772163391113,
      "learning_rate": 0.0036598079561042524,
      "loss": 0.0393,
      "step": 620
    },
    {
      "epoch": 0.8641975308641975,
      "grad_norm": 3.817784070968628,
      "learning_rate": 0.0036543209876543207,
      "loss": 0.0506,
      "step": 630
    },
    {
      "epoch": 0.877914951989026,
      "grad_norm": 1.6846778392791748,
      "learning_rate": 0.0036488340192043895,
      "loss": 0.0483,
      "step": 640
    },
    {
      "epoch": 0.8916323731138546,
      "grad_norm": 0.6752075552940369,
      "learning_rate": 0.0036433470507544583,
      "loss": 0.0302,
      "step": 650
    },
    {
      "epoch": 0.9053497942386831,
      "grad_norm": 0.5913817882537842,
      "learning_rate": 0.0036378600823045266,
      "loss": 0.0677,
      "step": 660
    },
    {
      "epoch": 0.9190672153635117,
      "grad_norm": 0.4712817370891571,
      "learning_rate": 0.0036323731138545954,
      "loss": 0.0311,
      "step": 670
    },
    {
      "epoch": 0.9327846364883402,
      "grad_norm": 0.5882495641708374,
      "learning_rate": 0.003626886145404664,
      "loss": 0.0364,
      "step": 680
    },
    {
      "epoch": 0.9465020576131687,
      "grad_norm": 7.433635234832764,
      "learning_rate": 0.0036213991769547325,
      "loss": 0.0494,
      "step": 690
    },
    {
      "epoch": 0.9602194787379973,
      "grad_norm": 3.19130802154541,
      "learning_rate": 0.0036159122085048013,
      "loss": 0.0379,
      "step": 700
    },
    {
      "epoch": 0.9739368998628258,
      "grad_norm": 1.097072720527649,
      "learning_rate": 0.0036104252400548697,
      "loss": 0.0248,
      "step": 710
    },
    {
      "epoch": 0.9876543209876543,
      "grad_norm": 3.953758955001831,
      "learning_rate": 0.0036049382716049384,
      "loss": 0.0362,
      "step": 720
    }
  ],
  "logging_steps": 10,
  "max_steps": 7290,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 0.0,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
